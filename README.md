<p align="center">
<a href="https://renat.semaphoreci.com/projects/Future-Laravel"><img src="https://renat.semaphoreci.com/badges/Future-Laravel/branches/main.svg?style=shields" alt="Build Status"></a>
</p>

## О приложении Future-Laravel

Представляет из себя REST API-бэкенд телефонной книги.

## Развертывание

# Перед установкой
- docker-compose должен быть установлен. Крайне нежелательно устанавливать его в виде snap'а, в этом случае работу может заметно затруднить AppArmor.
- Docker-desktop должен быть установлен и запущен.
- GIT должен быть установлен.
- Порты 80 и 5432 должны быть свободны. Если данные порты занимают установленные в host-ОС веб-сервер и сервер БД, потребуется их остановить.

# Установка
- В терминале перейдите в папку, в которой желаете разместить код приложения.
- git clone https://github.com/renatus/Future-Laravel.git
- В терминале перейдите в папку Future-Laravel/laradock-futurelara
- docker-compose up -d apache2
При первом запуске приложения building может занять много времени; последующие запуски осуществляются быстро. После завершения процесса сервис должен быть доступен на localhost'е, необходимые права на файлы и папки приложения выставляются автоматически, автоматически же создается БД и необходимая структура таблиц.

# Остановка
- docker-compose down

## Описание функционала

# Swagger
http://localhost/api/documentation

# Публично доступны:
- [Регистрация нового пользователя](http://localhost/v1/register)
Адрес электронной почты должен быть валидным (включая успешную проверку DNS-серверов домена) и уникальным среди всех пользователей. Пароль ограничен только длиной, на "боевом" проекте потребовалось бы поднять требования к его сложности. В случае успешной регистрации выдается bearer token.
- [Вход пользователя](http://localhost/v1/login)
В случае успешного входа выдается bearer token. В случае, если залогиниться не удалось, в ответе не сообщается, что именно не так, т.к. раскрытие потенциальному злоумышленнику информации о том, что данный адрес электронной почты в системе зарегистрирован, может быть серьезной проблемой безопасности.
- [Просмотр отдельной карточки контакта](http://localhost/v1/notebook/{uuid})
На "боевом" проекте добавил бы ссылки на скачивание не только полноразмерного фото, но и нескольких размеров thumbnail'ов, дабы снизить трафик на сервере и клиенте. Сейчас карточки доступны незарегистрированным пользователям, поэтому выбран публичный storage, но для настоящего API телефонной книги это было б неприемлемо в подавляющем большинстве случаев, общедоступность аватар контактов - страшная уязвимость.
- [Просмотр всех карточек контактов](http://localhost/v1/notebook)
Пользователь может опционально запросить выдачу предпочтительного для него количества карточек на странице, но не менее и не более, чем разрешено в .env-файле:
```shell
FUTURE_PAGINATION_MIN=3
FUTURE_PAGINATION_MAX=100
FUTURE_PAGINATION_DEF=5
```
Это позволяет минимизировать число запросов к серверу, в то же время избегая неадекватной нагрузки, когда клиент решит запросить сразу миллион записей, или, напротив, получать их по одной. Если предпочтительное число записей не задано, или оно выходит за границы разрешенного диапазона, выдается стандартное их количество.

# Зарегистрированным пользователям доступны:
- [Добавление отдельной карточки контакта](http://localhost/v1/notebook)
Адрес электронной почты должен быть валидным (включая успешную проверку DNS-серверов домена) и уникальным среди всех контактов.
Пользователь может опционально указать UUID записи. Это позволяет полноценно использовать клиент в оффлайн-режиме, а также сильно улучшает пользовательский опыт, если связь нестабильна, или бэкенд перегружен. К тому же эту перегрузку можно сделать менее вероятной, если запросы на добавление/модификацию/удаление сразу не отправлять, а агрегировать. Загруженная фотография, во-первых, валидируется, во-вторых, уменьшается до заданного размера (без апскейлинга, хотя для реальной телефонной книги он был бы, возможно, полезен, дабы все аватарки были одного размера). Максимальный размер стороны задается в .env-файле:
```shell
FUTURE_IMAGESIDE_DEF=200
```
Файл сохраняется в паках ГГГГ/ММ, что предотвращает проблемы с производительностью файловой системы (а они могут возникнуть уже при десятке тысяч элементов в одной папке), а также заметно упрощает инкрементальные бэкапы, достаточно скопировать только те папки, кои ранее не копировались, не придется проверять в БД, когда чего добавлено. Пользовательское название файла не сохраняется, т.к. может быть вектором атаки, да и модифицировать его все равно пришлось бы во избежание коллизий. К тому же кастомное, уникальное название позволяет клиентам понять, что файл обновился, и его надо скачать, просто сравнив текущий и предыдущий URL'ы.
- [Изменение отдельной карточки контакта](http://localhost/v1/notebook/{uuid})
Только пользователь, создавший карточку, может ее модифицировать.
Пользователь должен указать, когда в последний раз карточка была модифицирована на сервере. Если время модификации отличается от того, что указано в БД, модификация проведена не будет, пользователю будет предложено скачать обновленную версию с сервера, и работать уже с ней. Запросы типа POST используются потому, что это прямо требуется в задании, если бы такого требования не было, выбрал бы PATCH. Модификация осуществляется именно по PATCH-, а не по PUT-принципу, т.е. пользователь отправляет только модифицированные данные, неизменные не отправляет. Такой подход сильно снижает нагрузку как на сервере, так и на клиенте, гонять туда-сюда ту же фотографию пользователя было бы совершенно нецелесообразно. Для того, чтобы удалить информацию и оставить поле пустым, надо пересылать null, в случае с файлом в Postman'е поле надо для этого переключить в режим "текст" из режима "файл", иначе картинка не удаляется.
Если одна картинка заменяется другой, старый файл удаляется, новый файл сохраняется в папке, соответствующей текущему месяцу. Это нужно для инкрементальных бэкапов.
- [Удаление отдельной карточки контакта](http://localhost/v1/notebook/{uuid})
Только пользователь, создавший карточку, может ее удалить.
При удалении карточки не проводится проверка, не была ли она модифицирована другим клиентом? На реальном проекте данный аспект логики уточнил бы у product owner'а.
- [Выход пользователя](http://localhost/v1/logout)
Инвалидируется лишь используемый в данный момент токен, остальные сохраняются, что полезно в том случае, если клиент залогинен с нескольких устройств, а разлогиниться хочет лишь на одном. В реальном проекте добавил бы и возможность инвалидации всех относящихся к пользователю токенов.

Число запросов от одного пользователя в минуту ограничено, значение выставляется в .env-файле
```shell
FUTURE_REQUEST_MAX_NUMBER=10
```
Если предельное число запросов достигнуто, клиенту будет сообщено, через сколько секунд можно повторить запрос. Такой метод поможет ограничить нагрузку лишь от легитимных клиентов, и, возможно, от наименее опытных злоумышленников. Серьезную DDOS-атаку надо "рубить" на гораздо более дальних подходах.
На "боевом" проекте добавил бы разные ограничения в зависимости от присвоенной пользователю роли, а также ограничивал бы число запросов не только в минуту, но и в час.



## Тестирование

Ручное тестирование осуществлял с помощью [Postman](https://www.postman.com/blue-zodiac-836848-1/workspace/future-api/overview), и, в финале, с помощью веб-интерфейса Swagger. Предпочтение Postman'у отдаю потому, что Swagger не позволяет удобно тестировать заведомо некорректные запросы, да и добавлен Swagger был мною в самом конце.

Также написал PHPUnit'овские feature-тесты, кои запускал локально перед тем, как коммитить изменения. 
```shell
php artisan test
```
После коммита эти же тесты, вместе с рядом других проверок, выполняются в ВМ [Semaphore CI](https://renat.semaphoreci.com/projects/Future-Laravel).



## Известные проблемы

- Абсолютно недопустимо "светить" в публичном репозитории credentials базы данных, APP_KEY и т.д. Все это было немедленно зафиксировано мониторящими github скриптами. Однако в данном случае приложение будет лишь локально тестироваться, так что риска не вижу. На реальном проекте либо задал бы все "руками", либо использовал соответствующие CI/CD инструменты.

- Шелл-скрипт, осуществляющий подготовку Laravel-приложения к работе, инициализируется при запуске контейнера "workspace". В результате artisan'овские миграции выполняются при каждом старте контейнера, что в некоторых ситуациях может быть нежелательно. К тому же пришлось прибегнуть к ugly hack'у - добавить команду 
```shell
tail -f /dev/null
```
дабы контейнер "workspace" продолжал работать и после выполнения стартового скрипта.


Правильнее было б выделить для шелл-скрипта отдельный контейнер, который бы установил соединение с workspace'ом, выдал бы необходимые команды, и завершил работу. В таком случае не потребовалось бы использовать tail, а пользователь мог решить, нужна ли в данный конкретный момент "предстартовая подготовка" Laravel'я, или нет, запуская или не запуская этот служебный контейнер.

- В ходе "предстартовой подготовки" приложения приходится выставлять неадекватно высокие разрешения для подпапок в "storage", при попытках записи логов даже в папку с "rwxrwxrw" возникает ошибка. Убрать права на выполнение не удалось даже в папке для загружаемых файлов, на "боевом" сервере такая ситуация была бы абсолютно неприемлемой.

Laradock, с помощью которого приложение было докеризовано, работает с ownership'ом, но, очевидно, требуются дополнительные настройки.

- Laradock приносит с собой огромное количество самого разнообразного софта, большая часть которого проекту совершенно не требуется, но быстро удалить все ненужное невозможно, система перестает функционировать. В документации нет списка того, что можно безболезненно удалить, надо будет экспериментально проверить.

- Генерируемые при выполнении тестов файлы сохраняются не в тестовой filesystem, а в "боевой". Более того, на реальных проектах я выполняю такие тесты и в продакшене. Решение очень неоднозначное, однако неоднократно позволяло выявить проблемы с ФС. В-частности в данном случае тесты показали, что в виртуальной машине SemaphoreCI по невыясненной пока мною причине не работают Storage::exists() и Storage::delete(), хотя в локальном Docker'е проблем нет. Пришлось их заменить на file_exists() и unlink(). Эмулированная ФС позволяет проблему увидеть не всегда. Поэтому на своих проектах тестировал "боевую", предварительно удостоверившись в работоспособности бэкапов.

- PHPUnit хорошо интегрирован с Laravel, что упрощает написание тестов, но несколько снижает доверие к их результатам - в-частности потому, что реальный запрос к API не выполняется, а только имитируется. На серьезном проекте я бы тестировал именно реальные запросы, причем, желательно, из разных стран, чтоб поймать такие проблемы, как блокирование трафика всякими Cloudflare. Это и раньше было актуально, а уж сейчас, когда связанность Сети падает, еще важнее.



## Разное

- В подпапку V1, соответствующую первой версии API, вынес только файлы контроллеров. На реальном проекте собирал бы информацию о том, как часто и как глубоко API может меняться. С одной стороны, возможна ситуация, когда изменения будут частыми и глубокими, а поддерживать старые версии надо очень долго, тогда версионировать придется примерно все. Но в таком случае либо придется все дублировать - и править свежеобнаруженную уязвимость в тридцати местах, а не в одном, либо, условно, из контроллера V30 использовать функции из v16 и v7, поддерживать все это будет еще более тяжело. Поэтому предположил простой вариант - изменения предполагаются нерадикальные, поддерживаем одну-две предыдущих версии.

- Пагинацию выбрал курсорную, т.к. она весьма производительна, если записей много, а сортировки нет, к тому же нет проблем с дублями и пропущенными записями при добавлении или удалении записей между запросами. Однако если б было требование сделать сортировку по имени, компании и т.д., я бы подумал и об оффсетной.

- Выделил все манипуляции (добавление, модификация, удаление, листинг и т.д.) над всеми моделями в отдельные контроллеры. В тех проектах, над которыми работал в качестве единственного разработчика я бы скорее создал два контроллера - notebook и user - но в том случае, если разработчиков будет много, мне показалось правильным максимально распределить код по разным файлам, чтобы уменьшить вероятность merge conflict'ов. К тому же Swagger-комментарии добавляют файлам изрядно объема, пусть формально это и не код.

- После успешного удаления записи возвращается статус-код 410, не все согласны с тем, что это хорошая идея, т.к. данный код числится "ошибочным". На реальном проекте учитывал бы принятые в нем стандарты.

- В ответе, получаемом в ответ на запрос, информация частично дублируется. Например, в том же самом ответе с 410 кодом будет и текстовое описание результата - 'Entry deleted.'. Причина в том, что бэкенды на триллион запросов в час я никогда не делал, в моих проектах клиенты всегда предпочитали максимальную наглядность и понятность, цена в виде небольшого на их нагрузках оверхеда никого не смущала. Однако если бы речь шла о высоконагруженном сервисе, всю лишнюю информацию пришлось бы убрать.

- Довольно многословными в моих проектах бывают и комментарии, и readme. Не во всех проектах это поощряется, т.к. комментарии могут "протухать", а опытному разработчику текстовое разъяснение элементарных вещей не требуется. Однако на моих проектах клиенты "многословность" зачастую хвалили, а негатива к ней не было никогда, поэтому так и комментирую. В данном тестовом задании комментировал по такому же принципу - проверяющему "разжевывание" не требуется, однако ему может быть интересно, почему было выбрано то или иное решение.